
[general]

## which methods to include (boolean)
sequence_removal = True
duplicate_removal = True

## the bash command you would use to start samtools
samtools_bashcommand = qrsh -cwd -q medium_jobs.q -v BASH_ENV='~/.bashrc' -now n samtools

[sequence_removal]

## the bash command you would use to start bowtie2
bowtie2_bashcommand = qrsh -cwd -q medium_jobs.q -v BASH_ENV='~/.bashrc' -now n bowtie2

[alignment]

## the bash command you would use to start gsnap and gmap_build
gmap_build_bashcommand = qrsh -cwd -q medium_jobs.q -v BASH_ENV='~/.bashrc' -now n /net/isi-backup/yangl/tools/gmap/bin/gmap_build
gsnap_bashcommand = qrsh -cwd -q newnodes.q -v BASH_ENV='~/.bashrc' -now n /net/isi-backup/yangl/tools/gmap/bin/gsnap

## extra gsnap options
# nthreads is going to effect your number of parallels!
gsnap_nthreads = 2

## use preliminary alignment to long exons to determine average insert length (boolean)
# this includes production of a gff3 file from gtf, and a preliminary running of gsnap which may take a while
# if you already have a gff3 file available this should be placed with the gtf file, named the same but with the extension .gff3 - if this is possible this is adviced. The gtf to gff converter in this pipeline needs improving
determine_insert_size = False

## if determine_insert is set to True
# user defined arbitrarily large value for long exons (should be larger than expected fragment size)
long_exon_length = 1000
# the bash command you would use to start misos exon_utils
# (this should include the python segment of the command line, e.g. python2.6 exon_utils.py)
exon_utils_bashcommand = nice -19 python /net/isi-software/src/misopy-0.4.5/misopy/exon_utils.py
# the bash command you would use to start misos pe_utils
# (this should include the python segment of the command line, e.g. python2.6 pe_utils.py)
pe_utils_bashcommand = nice -19 python /net/isi-software/src/misopy-0.4.5/misopy/pe_utils.py

# if determine_insert is set to False, user defined average insert length and stdev
average_insert = 116
insert_dev = 85

[duplicate_removal]

## the bash command you would use to start python
python_bashcommand = qrsh -cwd -q newnodes.q -v BASH_ENV='~/.bashrc' -now n python

## the bash command you would use to start picard-tools MarkDuplicates
picard_bashcommand = qrsh -cwd -q medium_jobs.q -v BASH_ENV='~/.bashrc' -now n java -jar /net/isi-software/src/picard-tools-1.49/MarkDuplicates.jar

# the maximum number of file handles for the read ends map
max_filehandles = 1000

[HTSeq]

## the bash command you would use to sort in bash (usually just 'sort')
sort_bashcommand = qrsh -cwd -q medium_jobs.q -v BASH_ENV='~/.bashrc' -now n sort

## the bash command you would use to start htseq-count
htseq_bashcommand = htseq-count

[DESeq_EdgeR]

## Expansive level for pairwise comparisons:
# expansive = 1. Simply compares every single tissue/condition pairwise
# expansive = 2. Does above, plus compares each tissue/condition versus all others together
# expansive = 3. Does all of above, plus compares all different possible groupings with one another
# (expansive 3 not advised for comparisons of large numbers of groups, e.g. > 7, as this produces large outputs)
expansive = 3

## False Discovery Rate threshold to use
fdr = 0.05






